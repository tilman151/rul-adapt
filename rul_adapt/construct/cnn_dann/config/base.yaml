dm:
  source:
    _target_: rul_datasets.CmapssReader
    window_size: 30
    fd: ???
  target:
    fd: ???
    percent_broken: 1.0
  batch_size: 512

feature_extractor:
  _convert_: all  # needed for tensorboard hparam dumping
  _target_: rul_adapt.model.CnnExtractor
  input_channels: 14
  units: [10, 10, 10, 10, 1]
  seq_len: 30
  kernel_size: 10
  padding: True
  act_func: torch.nn.Tanh

regressor:
  _target_: rul_adapt.model.wrapper.DropoutPrefix
  wrapped:
    _convert_: all
    _target_: rul_adapt.model.FullyConnectedHead
    input_channels: 30
    act_func_on_last_layer: False
    act_func: torch.nn.Tanh
    units: [100, 1]
  dropout: 0.5

domain_disc:
  _convert_: all
  _target_: rul_adapt.model.FullyConnectedHead
  input_channels: 30
  act_func_on_last_layer: False
  units: [32, 1]
  act_func: torch.nn.Tanh

dann:
  _convert_: all
  _target_: rul_adapt.approach.DannApproach
  dann_factor: 3.0
  lr: 0.001
  loss_type: rmse
  optim_type: adam
  optim_betas: [0.5, 0.999]

trainer:
  _target_: pytorch_lightning.Trainer
  max_epochs: 125
  callbacks:
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      save_top_k: 1
      monitor: "val/target/rmse/dataloader_idx_1"
      mode: min