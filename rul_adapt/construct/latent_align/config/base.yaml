dm:
  source:
    _target_: ???
    fd: ???
    window_size: ???
  target:
    _target_: ${dm.source._target_}
    fd: ???
    window_size: ${dm.source.window_size}
  kwargs:
    batch_size: 128
  adaption_kwargs:
    inductive: True

feature_extractor:
  _convert_: all  # needed for tensorboard hparam dumping
  _target_: rul_adapt.model.CnnExtractor
  input_channels: ???
  units: [32, 16, 1]
  seq_len: ${dm.source.window_size}
  fc_units: 256
  fc_dropout: 0.5
  act_func: torch.nn.LeakyReLU
  fc_act_func: torch.nn.LeakyReLU

regressor:
  _convert_: all
  _target_: rul_adapt.model.FullyConnectedHead
  input_channels: ${feature_extractor.fc_units}
  act_func_on_last_layer: False
  units: [1]

latent_align:
  _target_: rul_adapt.approach.LatentAlignApproach
  alpha_healthy: 1.0
  alpha_direction: 1.0
  alpha_level: 1.0
  alpha_fusion: 1.0
  labels_as_percentage: True
  lr: 5e-4

trainer:
  _target_: pytorch_lightning.Trainer
  max_epochs: 2000