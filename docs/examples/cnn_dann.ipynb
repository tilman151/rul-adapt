{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN DANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:00:28.983541085Z",
     "start_time": "2023-11-16T14:00:28.967329196Z"
    }
   },
   "outputs": [],
   "source": [
    "import rul_adapt\n",
    "import rul_datasets\n",
    "import pytorch_lightning as pl\n",
    "import omegaconf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce original configurations\n",
    "\n",
    "You can reproduce the original experiments of Krokotsch et al. by using the `get_cnn_dann` constructor function.\n",
    "Known differences to the original are:\n",
    "\n",
    "* the model with the best validation RMSE is saved instead of the model with the best test RMSE.\n",
    "\n",
    "In this example, we re-create configuration for adaption CMAPSS FD003 to FD001.\n",
    "Additional `kwargs` for the trainer, e.g. `accelerator=\"gpu\"` for training on a GPU, can be passed to this function, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:00:29.101687264Z",
     "start_time": "2023-11-16T14:00:28.973912067Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42, workers=True)  # make reproducible\n",
    "dm, dann, trainer = rul_adapt.construct.get_cnn_dann(3, 1, max_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The networks, `feature_extractor`, `regressor`, `domain_disc`, can be accessed as properties of the `dann` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:00:29.102039411Z",
     "start_time": "2023-11-16T14:00:29.101468753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "CnnExtractor(\n  (_layers): Sequential(\n    (conv_0): Sequential(\n      (0): Conv1d(14, 10, kernel_size=(10,), stride=(1,), padding=same)\n      (1): Tanh()\n    )\n    (conv_1): Sequential(\n      (0): Conv1d(10, 10, kernel_size=(10,), stride=(1,), padding=same)\n      (1): Tanh()\n    )\n    (conv_2): Sequential(\n      (0): Conv1d(10, 10, kernel_size=(10,), stride=(1,), padding=same)\n      (1): Tanh()\n    )\n    (conv_3): Sequential(\n      (0): Conv1d(10, 10, kernel_size=(10,), stride=(1,), padding=same)\n      (1): Tanh()\n    )\n    (conv_4): Sequential(\n      (0): Conv1d(10, 1, kernel_size=(10,), stride=(1,), padding=same)\n      (1): Tanh()\n    )\n    (5): Flatten(start_dim=1, end_dim=-1)\n  )\n)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dann.feature_extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is done in the PyTorch Lightning fashion.\n",
    "We used the `trainer_kwargs` to train only one epoch for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:00:31.519051474Z",
     "start_time": "2023-11-16T14:00:29.133710300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name               | Type                  | Params\n",
      "-------------------------------------------------------------\n",
      "0 | train_source_loss  | MeanSquaredError      | 0     \n",
      "1 | evaluator          | AdaptionEvaluator     | 0     \n",
      "2 | _feature_extractor | CnnExtractor          | 4.5 K \n",
      "3 | _regressor         | DropoutPrefix         | 3.2 K \n",
      "4 | dann_loss          | DomainAdversarialLoss | 1.0 K \n",
      "-------------------------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa719077fe4b41609121ccf8d1d6a215"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tilman/Programming/rul-adapt/.venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9877335865124c9ea94a9b7e55937e33"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2445d7efd12d44c4b0f6d2844ebab8d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/tilman/Programming/rul-adapt/docs/examples/lightning_logs/version_21/checkpoints/epoch=0-step=35.ckpt\n",
      "Loaded model weights from checkpoint at /home/tilman/Programming/rul-adapt/docs/examples/lightning_logs/version_21/checkpoints/epoch=0-step=35.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5411a38e032b4e89bcb8486b2bd9fece"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0             DataLoader 1\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "    test/source/rmse         73.9958724975586\n",
      "    test/source/score          158354.40625\n",
      "    test/target/rmse                                  75.42831420898438\n",
      "    test/target/score                                   151000.71875\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'test/source/rmse/dataloader_idx_0': 73.9958724975586,\n  'test/source/score/dataloader_idx_0': 158354.40625},\n {'test/target/rmse/dataloader_idx_1': 75.42831420898438,\n  'test/target/score/dataloader_idx_1': 151000.71875}]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(dann, dm)\n",
    "trainer.test(ckpt_path=\"best\", datamodule=dm)  # loads the best model checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you only want to see the hyperparameters, you can use the `get_lstm_dann_config` function.\n",
    "This returns an `omegeconf.DictConfig` which you can modify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:00:31.598979723Z",
     "start_time": "2023-11-16T14:00:31.530833804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dm:\n",
      "  source:\n",
      "    _target_: rul_datasets.CmapssReader\n",
      "    window_size: 30\n",
      "    fd: 3\n",
      "  target:\n",
      "    fd: 1\n",
      "    percent_broken: 1.0\n",
      "  batch_size: 512\n",
      "feature_extractor:\n",
      "  _convert_: all\n",
      "  _target_: rul_adapt.model.CnnExtractor\n",
      "  input_channels: 14\n",
      "  units:\n",
      "  - 10\n",
      "  - 10\n",
      "  - 10\n",
      "  - 10\n",
      "  - 1\n",
      "  seq_len: 30\n",
      "  kernel_size: 10\n",
      "  padding: true\n",
      "  act_func: torch.nn.Tanh\n",
      "regressor:\n",
      "  _target_: rul_adapt.model.wrapper.DropoutPrefix\n",
      "  wrapped:\n",
      "    _convert_: all\n",
      "    _target_: rul_adapt.model.FullyConnectedHead\n",
      "    input_channels: 30\n",
      "    act_func_on_last_layer: false\n",
      "    act_func: torch.nn.Tanh\n",
      "    units:\n",
      "    - 100\n",
      "    - 1\n",
      "  dropout: 0.5\n",
      "domain_disc:\n",
      "  _convert_: all\n",
      "  _target_: rul_adapt.model.FullyConnectedHead\n",
      "  input_channels: 30\n",
      "  act_func_on_last_layer: false\n",
      "  units:\n",
      "  - 32\n",
      "  - 1\n",
      "  act_func: torch.nn.Tanh\n",
      "dann:\n",
      "  _convert_: all\n",
      "  _target_: rul_adapt.approach.DannApproach\n",
      "  dann_factor: 3.0\n",
      "  lr: 0.001\n",
      "  loss_type: rmse\n",
      "  optim_type: adam\n",
      "  optim_betas:\n",
      "  - 0.5\n",
      "  - 0.999\n",
      "trainer:\n",
      "  _target_: pytorch_lightning.Trainer\n",
      "  max_epochs: 125\n",
      "  callbacks:\n",
      "  - _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
      "    save_top_k: 1\n",
      "    monitor: val/target/rmse/dataloader_idx_1\n",
      "    mode: min\n"
     ]
    }
   ],
   "source": [
    "three2one_config = rul_adapt.construct.get_cnn_dann_config(3, 1)\n",
    "print(omegaconf.OmegaConf.to_yaml(three2one_config, resolve=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run your own experiments\n",
    "\n",
    "You can use the CNN DANN implementation to run your own experiments with different hyperparameters or on different datasets.\n",
    "Here we build a small LSTM DANN version for CMAPSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T14:00:44.404607001Z",
     "start_time": "2023-11-16T14:00:31.602212118Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name               | Type                  | Params\n",
      "-------------------------------------------------------------\n",
      "0 | train_source_loss  | MeanAbsoluteError     | 0     \n",
      "1 | evaluator          | AdaptionEvaluator     | 0     \n",
      "2 | _feature_extractor | LstmExtractor         | 2.2 K \n",
      "3 | _regressor         | FullyConnectedHead    | 81    \n",
      "4 | dann_loss          | DomainAdversarialLoss | 81    \n",
      "-------------------------------------------------------------\n",
      "2.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf718164c9b340cfa6ddd077cf0bc6b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2932e429b454ab0976cfff153a19e76"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67f7de3c109544b58e2dd4d55e6f9ea1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3495d1e032d84e2b9e6b457cbf98bde8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0             DataLoader 1\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "    test/source/rmse        20.788148880004883\n",
      "    test/source/score         3068.064453125\n",
      "    test/target/rmse                                  18.67778778076172\n",
      "    test/target/score                                1114.4984130859375\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'test/source/rmse/dataloader_idx_0': 20.788148880004883,\n  'test/source/score/dataloader_idx_0': 3068.064453125},\n {'test/target/rmse/dataloader_idx_1': 18.67778778076172,\n  'test/target/score/dataloader_idx_1': 1114.4984130859375}]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = rul_datasets.CmapssReader(3)\n",
    "target = source.get_compatible(1, percent_broken=0.8)\n",
    "dm = rul_datasets.DomainAdaptionDataModule(\n",
    "    rul_datasets.RulDataModule(source, batch_size=32),\n",
    "    rul_datasets.RulDataModule(target, batch_size=32),\n",
    ")\n",
    "\n",
    "feature_extractor = rul_adapt.model.LstmExtractor(\n",
    "    input_channels=14,\n",
    "    units=[16],\n",
    "    fc_units=8,\n",
    ")\n",
    "regressor = rul_adapt.model.FullyConnectedHead(\n",
    "    input_channels=8,\n",
    "    units=[8, 1],\n",
    "    act_func_on_last_layer=False,\n",
    ")\n",
    "domain_disc = rul_adapt.model.FullyConnectedHead(\n",
    "    input_channels=8,\n",
    "    units=[8, 1],\n",
    "    act_func_on_last_layer=False,\n",
    ")\n",
    "\n",
    "dann = rul_adapt.approach.DannApproach(\n",
    "    dann_factor=1.0, lr=0.001, optim_type=\"adam\"\n",
    ")\n",
    "dann.set_model(feature_extractor, regressor, domain_disc)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=1)\n",
    "\n",
    "trainer.fit(dann, dm)\n",
    "trainer.test(dann, dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
