{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN DANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-27T11:08:43.542662Z",
     "end_time": "2023-04-27T11:08:43.543086Z"
    }
   },
   "outputs": [],
   "source": [
    "import rul_adapt\n",
    "import rul_datasets\n",
    "import pytorch_lightning as pl\n",
    "import omegaconf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce original configurations\n",
    "\n",
    "You can reproduce the original experiments of Krokotsch et al. by using the `get_cnn_dann` constructor function.\n",
    "Known differences to the original are:\n",
    "\n",
    "* the model with the best validation RMSE is saved instead of the model with the best test RMSE.\n",
    "\n",
    "In this example, we re-create configuration for adaption CMAPSS FD003 to FD001.\n",
    "Additional `kwargs` for the trainer, e.g. `accelerator=\"gpu\"` for training on a GPU, can be passed to this function, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-27T11:08:43.542737Z",
     "end_time": "2023-04-27T11:08:43.612582Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42, workers=True)  # make reproducible\n",
    "dm, dann, trainer = rul_adapt.construct.get_cnn_dann(3, 1, max_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The networks, `feature_extractor`, `regressor`, `domain_disc`, can be accessed as properties of the `dann` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-27T11:08:43.614227Z",
     "end_time": "2023-04-27T11:08:43.617564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "CnnExtractor(\n  (_layers): Sequential(\n    (conv_0): Sequential(\n      (0): Conv1d(14, 10, kernel_size=(10,), stride=(1,), padding=same)\n      (1): Tanh()\n    )\n    (conv_1): Sequential(\n      (0): Conv1d(10, 10, kernel_size=(10,), stride=(1,), padding=same)\n      (1): Tanh()\n    )\n    (conv_2): Sequential(\n      (0): Conv1d(10, 10, kernel_size=(10,), stride=(1,), padding=same)\n      (1): Tanh()\n    )\n    (conv_3): Sequential(\n      (0): Conv1d(10, 10, kernel_size=(10,), stride=(1,), padding=same)\n      (1): Tanh()\n    )\n    (conv_4): Sequential(\n      (0): Conv1d(10, 1, kernel_size=(10,), stride=(1,), padding=same)\n      (1): Tanh()\n    )\n    (5): Flatten(start_dim=1, end_dim=-1)\n  )\n)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dann.feature_extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is done in the PyTorch Lightning fashion.\n",
    "We used the `trainer_kwargs` to train only one epoch for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-27T11:08:43.617913Z",
     "end_time": "2023-04-27T11:08:46.036333Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name               | Type                  | Params\n",
      "--------------------------------------------------------------\n",
      "0  | train_source_loss  | MeanSquaredError      | 0     \n",
      "1  | val_source_rmse    | MeanSquaredError      | 0     \n",
      "2  | val_target_rmse    | MeanSquaredError      | 0     \n",
      "3  | val_source_score   | RULScore              | 0     \n",
      "4  | val_target_score   | RULScore              | 0     \n",
      "5  | test_source_rmse   | MeanSquaredError      | 0     \n",
      "6  | test_target_rmse   | MeanSquaredError      | 0     \n",
      "7  | test_source_score  | RULScore              | 0     \n",
      "8  | test_target_score  | RULScore              | 0     \n",
      "9  | _feature_extractor | CnnExtractor          | 4.5 K \n",
      "10 | _regressor         | DropoutPrefix         | 3.2 K \n",
      "11 | dann_loss          | DomainAdversarialLoss | 1.0 K \n",
      "--------------------------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b83bea9c01f46be96cf058043ddbac8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tilman/Programming/rul-adapt/.venv/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (35) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c677b37875ad4e8bbfb43c1156372e84"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e0e16f04bfd4105a97bc5d1ebb96db9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/tilman/Programming/rul-adapt/examples/lightning_logs/version_31/checkpoints/epoch=0-step=35.ckpt\n",
      "Loaded model weights from checkpoint at /home/tilman/Programming/rul-adapt/examples/lightning_logs/version_31/checkpoints/epoch=0-step=35.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e48b1e024f2412498821277e3917adf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0             DataLoader 1\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "    test/source_rmse         73.99463653564453\n",
      "    test/source_score          158334.859375\n",
      "    test/target_rmse                                  75.43152618408203\n",
      "    test/target_score                                   151074.640625\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'test/source_rmse/dataloader_idx_0': 73.99463653564453,\n  'test/source_score/dataloader_idx_0': 158334.859375},\n {'test/target_rmse/dataloader_idx_1': 75.43152618408203,\n  'test/target_score/dataloader_idx_1': 151074.640625}]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(dann, dm)\n",
    "trainer.test(ckpt_path=\"best\", datamodule=dm)  # loads the best model checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you only want to see the hyperparameters, you can use the `get_lstm_dann_config` function.\n",
    "This returns an `omegeconf.DictConfig` which you can modify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T10:51:16.725778Z",
     "start_time": "2023-04-27T10:51:16.657906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dm:\n",
      "  source:\n",
      "    _target_: rul_datasets.CmapssReader\n",
      "    window_size: 30\n",
      "    fd: 3\n",
      "  target:\n",
      "    fd: 1\n",
      "    percent_broken: 1.0\n",
      "  batch_size: 512\n",
      "feature_extractor:\n",
      "  _target_: rul_adapt.model.CnnExtractor\n",
      "  input_channels: 14\n",
      "  conv_filters:\n",
      "  - 10\n",
      "  - 10\n",
      "  - 10\n",
      "  - 10\n",
      "  - 1\n",
      "  seq_len: 30\n",
      "  kernel_size: 10\n",
      "  padding: true\n",
      "  conv_act_func: torch.nn.Tanh\n",
      "regressor:\n",
      "  _target_: rul_adapt.model.wrapper.DropoutPrefix\n",
      "  wrapped:\n",
      "    _target_: rul_adapt.model.FullyConnectedHead\n",
      "    input_channels: 30\n",
      "    act_func_on_last_layer: false\n",
      "    act_func: torch.nn.Tanh\n",
      "    units:\n",
      "    - 100\n",
      "    - 1\n",
      "  dropout: 0.5\n",
      "domain_disc:\n",
      "  _target_: rul_adapt.model.FullyConnectedHead\n",
      "  input_channels: 30\n",
      "  act_func_on_last_layer: false\n",
      "  units:\n",
      "  - 32\n",
      "  - 1\n",
      "  act_func: torch.nn.Tanh\n",
      "dann:\n",
      "  _target_: rul_adapt.approach.DannApproach\n",
      "  dann_factor: 3.0\n",
      "  lr: 0.001\n",
      "  loss_type: rmse\n",
      "  optim_type: adam\n",
      "  adam_betas:\n",
      "  - 0.5\n",
      "  - 0.999\n",
      "trainer:\n",
      "  _target_: pytorch_lightning.Trainer\n",
      "  max_epochs: 125\n",
      "  callbacks:\n",
      "  - _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
      "    save_top_k: 1\n",
      "    monitor: val/target_rmse/dataloader_idx_1\n",
      "    mode: min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "three2one_config = rul_adapt.construct.get_cnn_dann_config(3, 1)\n",
    "print(omegaconf.OmegaConf.to_yaml(three2one_config, resolve=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run your own experiments\n",
    "\n",
    "You can use the CNN DANN implementation to run your own experiments with different hyperparameters or on different datasets.\n",
    "Here we build a small LSTM DANN version for CMAPSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T10:52:17.677556Z",
     "start_time": "2023-04-27T10:52:00.667644Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "   | Name               | Type                  | Params\n",
      "--------------------------------------------------------------\n",
      "0  | train_source_loss  | MeanAbsoluteError     | 0     \n",
      "1  | val_source_rmse    | MeanSquaredError      | 0     \n",
      "2  | val_target_rmse    | MeanSquaredError      | 0     \n",
      "3  | val_source_score   | RULScore              | 0     \n",
      "4  | val_target_score   | RULScore              | 0     \n",
      "5  | test_source_rmse   | MeanSquaredError      | 0     \n",
      "6  | test_target_rmse   | MeanSquaredError      | 0     \n",
      "7  | test_source_score  | RULScore              | 0     \n",
      "8  | test_target_score  | RULScore              | 0     \n",
      "9  | _feature_extractor | LstmExtractor         | 2.2 K \n",
      "10 | _regressor         | FullyConnectedHead    | 81    \n",
      "11 | dann_loss          | DomainAdversarialLoss | 81    \n",
      "--------------------------------------------------------------\n",
      "2.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9429042733488094065162472b3d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523682fa54164677a1633f5866570206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53fbbb1d7674e2ab30b9ddbd49dbbd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd5e3bbc56f4e49bc8a87549c3ba3f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0             DataLoader 1\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "    test/source_rmse        22.275436401367188\n",
      "    test/source_score        4992.75634765625\n",
      "    test/target_rmse                                 21.022199630737305\n",
      "    test/target_score                                 673.8871459960938\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test/source_rmse/dataloader_idx_0': 22.275436401367188,\n",
       "  'test/source_score/dataloader_idx_0': 4992.75634765625},\n",
       " {'test/target_rmse/dataloader_idx_1': 21.022199630737305,\n",
       "  'test/target_score/dataloader_idx_1': 673.8871459960938}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = rul_datasets.CmapssReader(3)\n",
    "target = source.get_compatible(1, percent_broken=0.8)\n",
    "dm = rul_datasets.DomainAdaptionDataModule(\n",
    "    rul_datasets.RulDataModule(source, batch_size=32),\n",
    "    rul_datasets.RulDataModule(target, batch_size=32),\n",
    ")\n",
    "\n",
    "feature_extractor = rul_adapt.model.LstmExtractor(\n",
    "    input_channels=14,\n",
    "    lstm_units=[16],\n",
    "    fc_units=8,\n",
    ")\n",
    "regressor = rul_adapt.model.FullyConnectedHead(\n",
    "    input_channels=8,\n",
    "    units=[8, 1],\n",
    "    act_func_on_last_layer=False,\n",
    ")\n",
    "domain_disc = rul_adapt.model.FullyConnectedHead(\n",
    "    input_channels=8,\n",
    "    units=[8, 1],\n",
    "    act_func_on_last_layer=False,\n",
    ")\n",
    "\n",
    "dann = rul_adapt.approach.DannApproach(\n",
    "    dann_factor=1.0, lr=0.001, optim_type=\"adam\"\n",
    ")\n",
    "dann.set_model(feature_extractor, regressor, domain_disc)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=1)\n",
    "\n",
    "trainer.fit(dann, dm)\n",
    "trainer.test(dann, dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
